{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the latent ODE model\n",
    "<strong>From appendix D</strong>\n",
    "\n",
    "To obtain the latent representation $z_{t_{0}}$, we traverse using RNN and obtain parameters of distribution $ q(\\textbf{z}_{t_{0}} | \\{ \\textbf{x}_{t_{i}}, t_{i} \\}_{i}, \\theta_{enc})$. The algorithm is the following:\n",
    "\n",
    "\n",
    "## Step 1\n",
    "Run an RNN encoder through the time series and infer the parameters for the a posterior over $ \\textbf{z}_{t_{0}}$:\n",
    "$$ q(\\textbf{z}_{t_{0}} | \\{ \\textbf{x}_{t_{i}}, t_{i} \\}_{i}, \\phi) = \\mathcal{N}(\\textbf{z}_{t_{0}} | \\mu_{\\textbf{z}_{t_{0}}}, \\sigma_{\\textbf{z}_{0}}) $$\n",
    "\n",
    "where $\\mu_{z_{0}}, \\sigma_{z_{0}}$ comes from hidden state of $ RNN(\\{ \\textbf{x}_{t_{i}} , t_{i} \\}_{i}, \\phi) $\n",
    "\n",
    "## Step 2\n",
    "Sample $ \\textbf{z}_{t_{0}} \\sim q(\\textbf{z}_{t_{0}} | \\{ \\textbf{x}_{t_{i}}, t_{i} \\}_{i}) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import autograd_extended\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Input, Lambda, Dense, RepeatVector\n",
    "from keras import backend as K\n",
    "from keras import objectives\n",
    "\n",
    "# obtain simple time series with sin function\n",
    "df = pd.read_csv('./data.csv')\n",
    "\n",
    "# split data into x_train, x_val, y_train, y_val\n",
    "ratio = 0.75\n",
    "idx = int(len(df) * ratio)\n",
    "df[1:20][\"x\"]\n",
    "x_train, x_test, y_train, y_test = df[:idx][\"x\"], df[idx:][\"x\"], df[:idx][\"y\"], df[:idx][\"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and run the autoencoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_45 (LSTM)               (None, 32)                4352      \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 100)               3300      \n",
      "=================================================================\n",
      "Total params: 7,652\n",
      "Trainable params: 7,652\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "repeat_vector_8 (RepeatVecto (None, 100, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_46 (LSTM)               (None, 100, 32)           17024     \n",
      "_________________________________________________________________\n",
      "lstm_47 (LSTM)               (None, 100, 1)            136       \n",
      "=================================================================\n",
      "Total params: 17,160\n",
      "Trainable params: 17,160\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      (None, 100, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_45 (LSTM)                  (None, 32)           4352        encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 100)          3300        lstm_45[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_52 (Dense)                (None, 100)          3300        lstm_45[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 100)          0           dense_51[0][0]                   \n",
      "                                                                 dense_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_7 (RepeatVector)  (None, 100, 100)     0           lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_46 (LSTM)                  (None, 100, 32)      17024       repeat_vector_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_47 (LSTM)                  (None, 100, 1)       136         lstm_46[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 28,112\n",
      "Trainable params: 28,112\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Run an RNN encoder on the time series\n",
    "\n",
    "# Params\n",
    "timesteps = 100\n",
    "input_dim = 1\n",
    "lstm_dim = 32\n",
    "latent_dim = 100\n",
    "batch_size = 1\n",
    "x_train.reshape = (-1, timesteps, 1)  # we make 100 samples\n",
    "y_train.reshape = (-1, timesteps, 1)\n",
    "x_test.reshape = (-1, timesteps, 1)\n",
    "y_test.reshape = (-1, timesteps, 1)\n",
    "\n",
    "\n",
    "# Encoder model\n",
    "def sample_z(args):\n",
    "    \"\"\"Reparameterization trick by sampling fr an isotropic unit Gaussian.\n",
    "    # Arguments:\n",
    "        args (tensor): mean and log of variance of Q(z|X)\n",
    "    # Returns:\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean=0 and std=1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "# Input\n",
    "inputs = Input(shape=(timesteps, input_dim,), name='encoder_input')\n",
    "\n",
    "# LSTM encoding\n",
    "h = LSTM(lstm_dim)(inputs)\n",
    "\n",
    "# VAE Z layer\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_sigma = Dense(latent_dim)(h)\n",
    "\n",
    "# Obtain z\n",
    "z = Lambda(sample_z, output_shape=(latent_dim,))([z_mean, z_log_sigma])\n",
    "\n",
    "encoder = Model(inputs, z_mean, name=\"encoder\")\n",
    "\n",
    "# Decoder model\n",
    "decoder_h = LSTM(lstm_dim, return_sequences=True)\n",
    "decoder_mean = LSTM(input_dim, return_sequences=True)\n",
    "\n",
    "h_decoded = RepeatVector(timesteps)(z)\n",
    "h_decoded = decoder_h(h_decoded)\n",
    "\n",
    "# decoded layer\n",
    "outputs = decoder_mean(h_decoded)\n",
    "\n",
    "# decoder, from latent space to reconstructed inputs\n",
    "decoder_inputs = Input(shape=(latent_dim,))\n",
    "\n",
    "_h_decoded = RepeatVector(timesteps)(decoder_inputs)\n",
    "_h_decoded = decoder_h(_h_decoded)\n",
    "\n",
    "decoder_outputs = decoder_mean(_h_decoded)\n",
    "\n",
    "decoder = Model(decoder_inputs, decoder_outputs)\n",
    "\n",
    "# Build vae\n",
    "vae = Model(inputs, outputs, name='vae_lstm')\n",
    "def vae_loss(x, x_decoded_mean):\n",
    "    xent_loss = objectives.mse(x, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma))\n",
    "    loss = xent_loss + kl_loss\n",
    "    return loss\n",
    "\n",
    "vae.compile(optimizer='adam', loss=vae_loss)\n",
    "\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the VAE to obtain z\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:catalyst]",
   "language": "python",
   "name": "conda-env-catalyst-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
